{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import m2cgen as m2c\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.63024</td>\n",
       "      <td>-0.14404</td>\n",
       "      <td>-0.03102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.64724</td>\n",
       "      <td>-0.14404</td>\n",
       "      <td>-0.03102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.64124</td>\n",
       "      <td>-0.14704</td>\n",
       "      <td>-0.03102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.64024</td>\n",
       "      <td>-0.14804</td>\n",
       "      <td>-0.03202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.64324</td>\n",
       "      <td>-0.15104</td>\n",
       "      <td>-0.03202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127870</th>\n",
       "      <td>-0.57778</td>\n",
       "      <td>-0.51798</td>\n",
       "      <td>-0.00540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127871</th>\n",
       "      <td>-0.57778</td>\n",
       "      <td>-0.51798</td>\n",
       "      <td>-0.00540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127872</th>\n",
       "      <td>-0.57778</td>\n",
       "      <td>-0.51798</td>\n",
       "      <td>-0.00540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127873</th>\n",
       "      <td>-0.57778</td>\n",
       "      <td>-0.51798</td>\n",
       "      <td>-0.00540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127874</th>\n",
       "      <td>-0.57778</td>\n",
       "      <td>-0.51798</td>\n",
       "      <td>-0.00540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127875 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2\n",
       "0      -0.63024 -0.14404 -0.03102\n",
       "1      -0.64724 -0.14404 -0.03102\n",
       "2      -0.64124 -0.14704 -0.03102\n",
       "3      -0.64024 -0.14804 -0.03202\n",
       "4      -0.64324 -0.15104 -0.03202\n",
       "...         ...      ...      ...\n",
       "127870 -0.57778 -0.51798 -0.00540\n",
       "127871 -0.57778 -0.51798 -0.00540\n",
       "127872 -0.57778 -0.51798 -0.00540\n",
       "127873 -0.57778 -0.51798 -0.00540\n",
       "127874 -0.57778 -0.51798 -0.00540\n",
       "\n",
       "[127875 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.read_csv(\"CSV_files/new_mvgavg+286.csv\",header=None)\n",
    "data2=pd.read_csv(\"CSV_files/new_mvgavg+136.csv\",header=None)\n",
    "data3=pd.read_csv(\"CSV_files/new_mvgavg+62.csv\",header=None)\n",
    "data4=pd.read_csv(\"CSV_files/new_mvgavg-62.csv\",header=None)\n",
    "data5=pd.read_csv(\"CSV_files/new_mvgavg-31.csv\",header=None)\n",
    "data6=pd.read_csv(\"CSV_files/new_mvgavg-24.csv\",header=None)\n",
    "data7=pd.read_csv(\"CSV_files/new_mvgavg-286.csv\",header=None)\n",
    "data8=pd.read_csv(\"CSV_files/new_mvgavg-136.csv\",header=None)\n",
    "\n",
    "\"\"\"columns1=[]\n",
    "for i in range(750):\n",
    "    if (i+2)%6==0 or (i+1)%6==0:\n",
    "        columns1.append(i)\n",
    "#print(columns)\"\"\"\n",
    "\n",
    "ones=np.ones((484,))\n",
    "zeroes=np.zeros((539,))\n",
    "binary=np.concatenate([ones,zeroes])\n",
    "pos=pd.concat([data1,data2,data3])\n",
    "neg=pd.concat([data4,data5,data6,data7,data8])\n",
    "step=pd.concat([pos,neg], ignore_index=True)\n",
    "X=np.array(step)\n",
    "X=X.reshape(1023,375)\n",
    "y=binary\n",
    "\n",
    "df=pd.DataFrame(step)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63024, -0.14404, -0.03102, ..., -0.64624, -0.18604, -0.03002],\n",
       "       [-0.64924, -0.15404, -0.02902, ..., -0.65924, -0.16004, -0.03002],\n",
       "       [-0.65524, -0.15304, -0.02902, ..., -0.65224, -0.16804, -0.02902],\n",
       "       ...,\n",
       "       [-0.59678, -0.45798, -0.0064 , ..., -0.58978, -0.52898, -0.0064 ],\n",
       "       [-0.60678, -0.51898, -0.0064 , ..., -0.90778,  0.01902, -0.0024 ],\n",
       "       [-0.61278, -0.49598, -0.0024 , ..., -0.57778, -0.51798, -0.0054 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "#X1=pd.DataFrame(StandardScaler().fit_transform(X))\n",
    "X1=pd.DataFrame(MinMaxScaler().fit_transform(X))\n",
    "#std=np.array(X1.std().sort_values())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(0.95)\n",
    "X_pca=pca.fit_transform(X1)\n",
    "len(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHWARYA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "Version 0.12.1 of tpot is outdated. Version 0.12.2 was released 7 days ago.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              \n",
      "Generation 1 - Current best internal CV score: 0.8985560377076164\n",
      "                                                                              \n",
      "Generation 2 - Current best internal CV score: 0.8985560377076164\n",
      "                                                                              \n",
      "Best pipeline: DecisionTreeClassifier(BernoulliNB(input_matrix, alpha=0.001, fit_prior=True), criterion=entropy, max_depth=7, min_samples_leaf=3, min_samples_split=5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(config_dict=&#x27;TPOT light&#x27;, generations=2, verbosity=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(config_dict=&#x27;TPOT light&#x27;, generations=2, verbosity=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(config_dict='TPOT light', generations=2, verbosity=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "fixed_model = {\n",
    "    'sklearn.ensemble.RandomForestClassifier': {\n",
    "    }\n",
    "}\n",
    "#model1=TPOTClassifier(verbosity=2,n_jobs=1,generations=2,config_dict='TPOT light')\n",
    "model1=TPOTClassifier(verbosity=2,n_jobs=1,generations=2,config_dict='TPOT light')\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X,y,test_size=0.2,stratify=y)\n",
    "model1.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9121951219512195"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y)\n",
    "#model4=DecisionTreeClassifier( criterion='gini', max_depth=8, min_samples_leaf=15, min_samples_split=13)\n",
    "model4=DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_leaf=3, min_samples_split=5)\n",
    "#model4.fit(X,y)\n",
    "model4.fit(X_train,y_train)\n",
    "model4.score(X_test,y_test)\n",
    "#test_data = pd.read_csv('newtestdata_neg3.csv',header=None)\n",
    "#fest_data=pd.read_csv('newtestdata_pos3.csv',header=None)\n",
    "#predictions = model4.predict(test_data)\n",
    "#model4.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#include <string.h>\\nvoid score(double * input, double * output) {\\n    double var0[2];\\n    if (input[93] <= -0.5979099869728088) {\\n        if (input[12] <= -0.6660099923610687) {\\n            if (input[26] <= 0.0189800001680851) {\\n                memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n            } else {\\n                memcpy(var0, (double[]){0.3333333333333333, 0.6666666666666666}, 2 * sizeof(double));\\n            }\\n        } else {\\n            if (input[161] <= -0.05234000086784363) {\\n                if (input[270] <= 0.4892899990081787) {\\n                    if (input[101] <= 0.16079000383615494) {\\n                        memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                    } else {\\n                        memcpy(var0, (double[]){0.4, 0.6}, 2 * sizeof(double));\\n                    }\\n                } else {\\n                    if (input[198] <= 3.695340096950531) {\\n                        memcpy(var0, (double[]){0.3333333333333333, 0.6666666666666666}, 2 * sizeof(double));\\n                    } else {\\n                        memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    }\\n                }\\n            } else {\\n                if (input[98] <= -0.02171000000089407) {\\n                    if (input[153] <= 0.47082000970840454) {\\n                        memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    } else {\\n                        if (input[282] <= 0.16729000210762024) {\\n                            memcpy(var0, (double[]){0.6, 0.4}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        }\\n                    }\\n                } else {\\n                    if (input[8] <= -0.038690000772476196) {\\n                        memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    } else {\\n                        memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                    }\\n                }\\n            }\\n        }\\n    } else {\\n        if (input[272] <= -0.05024999938905239) {\\n            if (input[363] <= 0.39229001104831696) {\\n                memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n            } else {\\n                if (input[140] <= -0.04725000075995922) {\\n                    memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                } else {\\n                    if (input[19] <= -0.2413799986243248) {\\n                        memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    } else {\\n                        memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                    }\\n                }\\n            }\\n        } else {\\n            if (input[90] <= 0.38352999091148376) {\\n                if (input[198] <= -0.6310099959373474) {\\n                    if (input[262] <= -0.322380006313324) {\\n                        if (input[125] <= -0.026209999807178974) {\\n                            memcpy(var0, (double[]){0.4, 0.6}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        }\\n                    } else {\\n                        if (input[265] <= 0.0867800023406744) {\\n                            memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        } else {\\n                            if (input[261] <= -0.19200999289751053) {\\n                                memcpy(var0, (double[]){0.16666666666666666, 0.8333333333333334}, 2 * sizeof(double));\\n                            } else {\\n                                memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                            }\\n                        }\\n                    }\\n                } else {\\n                    if (input[90] <= -0.1990099996328354) {\\n                        if (input[355] <= -0.3948799967765808) {\\n                            memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        } else {\\n                            if (input[346] <= 0.09627999924123287) {\\n                                memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                            } else {\\n                                memcpy(var0, (double[]){0.9090909090909091, 0.09090909090909091}, 2 * sizeof(double));\\n                            }\\n                        }\\n                    } else {\\n                        if (input[135] <= 0.3538200110197067) {\\n                            if (input[89] <= -0.0003499999875202775) {\\n                                memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                            } else {\\n                                memcpy(var0, (double[]){0.6666666666666666, 0.3333333333333333}, 2 * sizeof(double));\\n                            }\\n                        } else {\\n                            if (input[250] <= -0.06385999917984009) {\\n                                memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                            } else {\\n                                memcpy(var0, (double[]){0.3, 0.7}, 2 * sizeof(double));\\n                            }\\n                        }\\n                    }\\n                }\\n            } else {\\n                if (input[12] <= -0.3204699903726578) {\\n                    if (input[146] <= -0.02171000000089407) {\\n                        memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    } else {\\n                        if (input[334] <= -0.21250999718904495) {\\n                            memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var0, (double[]){0.6666666666666666, 0.3333333333333333}, 2 * sizeof(double));\\n                        }\\n                    }\\n                } else {\\n                    if (input[301] <= 0.2469800040125847) {\\n                        memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    } else {\\n                        if (input[88] <= -0.11822999641299248) {\\n                            memcpy(var0, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var0, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        }\\n                    }\\n                }\\n            }\\n        }\\n    }\\n    memcpy(output, var0, 2 * sizeof(double));\\n}\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_c = m2c.export_to_c(model4)  \n",
    "model_to_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9611650485436893"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,stratify=y)\n",
    "model=RandomForestClassifier(n_estimators=3)\n",
    "model.fit(X,y)\n",
    "#model.fit(X_train,y_train)\n",
    "#model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_data = pd.read_csv('noise.csv',header=None)\n",
    "#test_data=test_data.reshape(101,750)\n",
    "fest_data=np.array(pd.read_csv('pos_101.csv',header=None))\n",
    "predictions = model.predict(X_test)\n",
    "#model.score(X_test,y_test)\n",
    "model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#include <string.h>\\nvoid add_vectors(double *v1, double *v2, int size, double *result) {\\n    for(int i = 0; i < size; ++i)\\n        result[i] = v1[i] + v2[i];\\n}\\nvoid mul_vector_number(double *v1, double num, int size, double *result) {\\n    for(int i = 0; i < size; ++i)\\n        result[i] = v1[i] * num;\\n}\\nvoid score(double * input, double * output) {\\n    double var0[2];\\n    double var1[2];\\n    double var2[2];\\n    double var3[2];\\n    if (input[5] <= -0.3050000071525574) {\\n        if (input[381] <= -2.524999976158142) {\\n            if (input[121] <= -0.5700000077486038) {\\n                memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n            } else {\\n                memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n            }\\n        } else {\\n            if (input[238] <= 18.63499927520752) {\\n                if (input[333] <= 8.050000190734863) {\\n                    if (input[373] <= -15.78499984741211) {\\n                        memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                    } else {\\n                        if (input[478] <= 16.34500026702881) {\\n                            memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        }\\n                    }\\n                } else {\\n                    memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                }\\n            } else {\\n                if (input[279] <= -0.005000000819563866) {\\n                    memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                } else {\\n                    memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                }\\n            }\\n        }\\n    } else {\\n        if (input[147] <= -0.03499999921768904) {\\n            if (input[229] <= 0.6800000071525574) {\\n                memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n            } else {\\n                if (input[369] <= -0.044999999925494194) {\\n                    memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                } else {\\n                    memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                }\\n            }\\n        } else {\\n            if (input[89] <= 0.24499999731779099) {\\n                if (input[173] <= 0.44999998807907104) {\\n                    if (input[434] <= -7.7250001430511475) {\\n                        memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    } else {\\n                        if (input[229] <= 1.9749999642372131) {\\n                            if (input[441] <= -8.940000057220459) {\\n                                if (input[496] <= 1.6150000020861626) {\\n                                    memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                                } else {\\n                                    memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                                }\\n                            } else {\\n                                memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                            }\\n                        } else {\\n                            if (input[17] <= -0.29499999433755875) {\\n                                memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                            } else {\\n                                memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                            }\\n                        }\\n                    }\\n                } else {\\n                    if (input[44] <= 0.009999999776482582) {\\n                        memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    } else {\\n                        if (input[273] <= -2.0699999928474426) {\\n                            memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        }\\n                    }\\n                }\\n            } else {\\n                if (input[276] <= -4.790000081062317) {\\n                    if (input[151] <= 0.07500000018626451) {\\n                        memcpy(var3, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                    } else {\\n                        memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    }\\n                } else {\\n                    memcpy(var3, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                }\\n            }\\n        }\\n    }\\n    double var4[2];\\n    if (input[61] <= -0.5) {\\n        if (input[416] <= 16.28499984741211) {\\n            memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n        } else {\\n            if (input[67] <= 0.02500000037252903) {\\n                memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n            } else {\\n                memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n            }\\n        }\\n    } else {\\n        if (input[159] <= -0.03499999921768904) {\\n            if (input[456] <= 0.6150000095367432) {\\n                memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n            } else {\\n                if (input[198] <= 12.75499963760376) {\\n                    memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                } else {\\n                    memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                }\\n            }\\n        } else {\\n            if (input[85] <= 0.049999999813735485) {\\n                if (input[143] <= -0.014999999664723873) {\\n                    if (input[221] <= -0.3450000062584877) {\\n                        memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    } else {\\n                        if (input[333] <= -0.35999999940395355) {\\n                            memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        }\\n                    }\\n                } else {\\n                    if (input[147] <= -0.029999999329447746) {\\n                        if (input[473] <= -0.14499999582767487) {\\n                            memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        }\\n                    } else {\\n                        if (input[44] <= 1.8899999856948853) {\\n                            if (input[440] <= -2.3350000381469727) {\\n                                if (input[381] <= 1.305000051856041) {\\n                                    memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                                } else {\\n                                    memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                                }\\n                            } else {\\n                                if (input[285] <= -6.485000133514404) {\\n                                    if (input[265] <= 0.06499999761581421) {\\n                                        memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                                    } else {\\n                                        memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                                    }\\n                                } else {\\n                                    memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                                }\\n                            }\\n                        } else {\\n                            if (input[249] <= -0.5650000022724271) {\\n                                memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                            } else {\\n                                memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                            }\\n                        }\\n                    }\\n                }\\n            } else {\\n                if (input[314] <= 12.894999980926514) {\\n                    memcpy(var4, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                } else {\\n                    memcpy(var4, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                }\\n            }\\n        }\\n    }\\n    add_vectors(var3, var4, 2, var2);\\n    double var5[2];\\n    if (input[57] <= -0.4650000035762787) {\\n        memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n    } else {\\n        if (input[125] <= 0.029999999329447746) {\\n            if (input[190] <= 5.375) {\\n                if (input[71] <= 0.004999999888241291) {\\n                    memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                } else {\\n                    memcpy(var5, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                }\\n            } else {\\n                if (input[285] <= -0.39000000059604645) {\\n                    if (input[122] <= 9.944999694824219) {\\n                        if (input[404] <= 4.555000066757202) {\\n                            memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var5, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        }\\n                    } else {\\n                        if (input[150] <= 10.714999675750732) {\\n                            memcpy(var5, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        }\\n                    }\\n                } else {\\n                    if (input[137] <= 0.014999999664723873) {\\n                        if (input[288] <= -12.130000114440918) {\\n                            memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        } else {\\n                            memcpy(var5, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                        }\\n                    } else {\\n                        memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                    }\\n                }\\n            }\\n        } else {\\n            if (input[392] <= -0.8150000274181366) {\\n                memcpy(var5, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n            } else {\\n                if (input[12] <= 1.699999988079071) {\\n                    if (input[435] <= -0.014999999664723873) {\\n                        memcpy(var5, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                    } else {\\n                        if (input[264] <= 4.875) {\\n                            memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                        } else {\\n                            if (input[348] <= 0.5800000131130219) {\\n                                if (input[136] <= 0.8049999922513962) {\\n                                    memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                                } else {\\n                                    memcpy(var5, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                                }\\n                            } else {\\n                                memcpy(var5, (double[]){0.0, 1.0}, 2 * sizeof(double));\\n                            }\\n                        }\\n                    }\\n                } else {\\n                    memcpy(var5, (double[]){1.0, 0.0}, 2 * sizeof(double));\\n                }\\n            }\\n        }\\n    }\\n    add_vectors(var2, var5, 2, var1);\\n    mul_vector_number(var1, 0.3333333333333333, 2, var0);\\n    memcpy(output, var0, 2 * sizeof(double));\\n}\\n'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_c1 = m2c.export_to_c(model)  \n",
    "model_to_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAHHCAYAAAAf2DoOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABI/0lEQVR4nO3de1hU1f7H8c+AMqACooJAmVoWal6jUruIloVoJFne6hzw0s2sVNRMfydFrehnlmXesqPi6WiapWRmnuOdPF7yRqmn/Cmp1BG85Q3UkWD//vBxTjtAQWdm6/h+9eznadZee+3vTM/k1+9aa4/NMAxDAAAAHuJjdQAAAOD6QvIBAAA8iuQDAAB4FMkHAADwKJIPAADgUSQfAADAo0g+AACAR5F8AAAAjyL5AAAAHkXyAbjR7t279fDDDys4OFg2m03p6ekuHX/fvn2y2WxKS0tz6bjXsjZt2qhNmzZWhwHgIkg+4PWysrL03HPP6eabb5a/v7+CgoJ077336v3339eZM2fceu+kpCRt375db7zxhj7++GPdeeedbr2fJ/Xs2VM2m01BQUElfo67d++WzWaTzWbTuHHjyj3+gQMHlJKSoszMTBdEC+BqUsHqAAB3+uqrr9SlSxfZ7XYlJiaqUaNGOnfunNauXashQ4Zo586dmjZtmlvufebMGa1fv17/8z//oxdffNEt96hdu7bOnDmjihUrumX8S6lQoYJOnz6tL7/8Ul27djWdmz17tvz9/XX27NnLGvvAgQMaNWqU6tSpo2bNmpX5un/+85+XdT8AnkPyAa+1d+9ede/eXbVr19bKlSsVERHhPNevXz/t2bNHX331ldvuf/jwYUlS1apV3XYPm80mf39/t41/KXa7Xffee68++eSTYsnHnDlz1LFjR33++eceieX06dOqVKmS/Pz8PHI/AJePaRd4rbFjxyovL0/Tp083JR4X1KtXT/3793e+/u233zRmzBjdcsststvtqlOnjoYPHy6Hw2G6rk6dOnrkkUe0du1a3X333fL399fNN9+sv/3tb84+KSkpql27tiRpyJAhstlsqlOnjqTz0xUX/v33UlJSZLPZTG3Lli3Tfffdp6pVq6pKlSqKiorS8OHDnedLW/OxcuVK3X///apcubKqVq2qTp066Ycffijxfnv27FHPnj1VtWpVBQcHq1evXjp9+nTpH+wfPPnkk/r66691/PhxZ9umTZu0e/duPfnkk8X6//rrrxo8eLAaN26sKlWqKCgoSHFxcfruu++cfVavXq277rpLktSrVy/n9M2F99mmTRs1atRIW7ZsUevWrVWpUiXn5/LHNR9JSUny9/cv9v5jY2MVEhKiAwcOlPm9AnANkg94rS+//FI333yz7rnnnjL1f/rppzVixAjdcccdGj9+vGJiYpSamqru3bsX67tnzx498cQTeuihh/TOO+8oJCREPXv21M6dOyVJnTt31vjx4yVJPXr00Mcff6z33nuvXPHv3LlTjzzyiBwOh0aPHq133nlHjz76qP71r39d9Lrly5crNjZWhw4dUkpKipKTk7Vu3Trde++92rdvX7H+Xbt21alTp5SamqquXbsqLS1No0aNKnOcnTt3ls1m04IFC5xtc+bMUf369XXHHXcU6//TTz8pPT1djzzyiN59910NGTJE27dvV0xMjDMRaNCggUaPHi1JevbZZ/Xxxx/r448/VuvWrZ3jHD16VHFxcWrWrJnee+89tW3btsT43n//fYWGhiopKUmFhYWSpA8//FD//Oc/9cEHHygyMrLM7xWAixiAFzpx4oQhyejUqVOZ+mdmZhqSjKefftrUPnjwYEOSsXLlSmdb7dq1DUlGRkaGs+3QoUOG3W43Bg0a5Gzbu3evIcl4++23TWMmJSUZtWvXLhbDyJEjjd9/JcePH29IMg4fPlxq3BfuMXPmTGdbs2bNjLCwMOPo0aPOtu+++87w8fExEhMTi92vd+/epjEfe+wxo3r16qXe8/fvo3LlyoZhGMYTTzxhPPjgg4ZhGEZhYaERHh5ujBo1qsTP4OzZs0ZhYWGx92G3243Ro0c72zZt2lTsvV0QExNjSDKmTp1a4rmYmBhT2z/+8Q9DkvH6668bP/30k1GlShUjISHhku8RgHtQ+YBXOnnypCQpMDCwTP2XLFkiSUpOTja1Dxo0SJKKrQ1p2LCh7r//fufr0NBQRUVF6aeffrrsmP/owlqRL774QkVFRWW6JicnR5mZmerZs6eqVavmbG/SpIkeeugh5/v8veeff970+v7779fRo0edn2FZPPnkk1q9erVyc3O1cuVK5ebmljjlIp1fJ+Ljc/5/PYWFhTp69KhzSmnr1q1lvqfdblevXr3K1Pfhhx/Wc889p9GjR6tz587y9/fXhx9+WOZ7AXAtkg94paCgIEnSqVOnytR///798vHxUb169Uzt4eHhqlq1qvbv329qv+mmm4qNERISomPHjl1mxMV169ZN9957r55++mnVrFlT3bt316effnrRRORCnFFRUcXONWjQQEeOHFF+fr6p/Y/vJSQkRJLK9V46dOigwMBAzZs3T7Nnz9Zdd91V7LO8oKioSOPHj9ett94qu92uGjVqKDQ0VN9//71OnDhR5nvecMMN5VpcOm7cOFWrVk2ZmZmaMGGCwsLCynwtANci+YBXCgoKUmRkpHbs2FGu6/644LM0vr6+JbYbhnHZ97iwHuGCgIAAZWRkaPny5frzn/+s77//Xt26ddNDDz1UrO+VuJL3coHdblfnzp01a9YsLVy4sNSqhyS9+eabSk5OVuvWrfX3v/9d//jHP7Rs2TLdfvvtZa7wSOc/n/LYtm2bDh06JEnavn17ua4F4FokH/BajzzyiLKysrR+/fpL9q1du7aKioq0e/duU/vBgwd1/Phx584VVwgJCTHtDLngj9UVSfLx8dGDDz6od999V//+97/1xhtvaOXKlVq1alWJY1+Ic9euXcXO/fjjj6pRo4YqV658ZW+gFE8++aS2bdumU6dOlbhI94LPPvtMbdu21fTp09W9e3c9/PDDateuXbHPpKyJYFnk5+erV69eatiwoZ599lmNHTtWmzZtctn4AMqH5ANe65VXXlHlypX19NNP6+DBg8XOZ2Vl6f3335d0ftpAUrEdKe+++64kqWPHji6L65ZbbtGJEyf0/fffO9tycnK0cOFCU79ff/212LUXHrb1x+2/F0RERKhZs2aaNWuW6Q/zHTt26J///KfzfbpD27ZtNWbMGE2cOFHh4eGl9vP19S1WVZk/f77+85//mNouJEklJWrlNXToUGVnZ2vWrFl69913VadOHSUlJZX6OQJwLx4yBq91yy23aM6cOerWrZsaNGhgesLpunXrNH/+fPXs2VOS1LRpUyUlJWnatGk6fvy4YmJi9O2332rWrFlKSEgodRvn5ejevbuGDh2qxx57TC+//LJOnz6tKVOm6LbbbjMtuBw9erQyMjLUsWNH1a5dW4cOHdLkyZN144036r777it1/LfffltxcXFq1aqV+vTpozNnzuiDDz5QcHCwUlJSXPY+/sjHx0d/+ctfLtnvkUce0ejRo9WrVy/dc8892r59u2bPnq2bb77Z1O+WW25R1apVNXXqVAUGBqpy5cpq0aKF6tatW664Vq5cqcmTJ2vkyJHOrb8zZ85UmzZt9Nprr2ns2LHlGg+AC1i82wZwu//7v/8znnnmGaNOnTqGn5+fERgYaNx7773GBx98YJw9e9bZr6CgwBg1apRRt25do2LFikatWrWMYcOGmfoYxvmtth07dix2nz9u8Sxtq61hGMY///lPo1GjRoafn58RFRVl/P3vfy+21XbFihVGp06djMjISMPPz8+IjIw0evToYfzf//1fsXv8cTvq8uXLjXvvvdcICAgwgoKCjPj4eOPf//63qc+F+/1xK+/MmTMNScbevXtL/UwNw7zVtjSlbbUdNGiQERERYQQEBBj33nuvsX79+hK3yH7xxRdGw4YNjQoVKpjeZ0xMjHH77beXeM/fj3Py5Emjdu3axh133GEUFBSY+g0cONDw8fEx1q9ff9H3AMD1bIZRjlVlAAAAV4g1HwAAwKNIPgAAgEeRfAAAAI8i+QAAAB5F8gEAADyK5AMAAHgUyQcAAPAor3zC6dnfrI4AuDqF3PWi1SEAV50z2ya6/R4BzV3z3fNErJ5A5QMAAHiUV1Y+AAC4qtj4u/7vkXwAAOBuNpvVEVxVSD4AAHA3Kh8mfBoAAMCjqHwAAOBuTLuYkHwAAOBuTLuY8GkAAACPovIBAIC7Me1iQvIBAIC7Me1iwqcBAAA8isoHAADuxrSLCckHAADuxrSLCZ8GAADwKCofAAC4G9MuJiQfAAC4G9MuJiQfAAC4G5UPE1IxAADgUVQ+AABwN6ZdTEg+AABwN5IPEz4NAADgUVQ+AABwNx8WnP4eyQcAAO7GtIsJnwYAAPAoKh8AALgbz/kwIfkAAMDdmHYx4dMAAAAeReUDAAB3Y9rFhMoHAADuZvNxzVEOqampuuuuuxQYGKiwsDAlJCRo165dpj5nz55Vv379VL16dVWpUkWPP/64Dh48eNFxDcPQiBEjFBERoYCAALVr1067d+8uV2wkHwAAuJvN5pqjHNasWaN+/fppw4YNWrZsmQoKCvTwww8rPz/f2WfgwIH68ssvNX/+fK1Zs0YHDhxQ586dLzru2LFjNWHCBE2dOlUbN25U5cqVFRsbq7Nnz5b94zAMwyjXu7kGnP3N6giAq1PIXS9aHQJw1TmzbaLb7xEQO84l45z5x+DLvvbw4cMKCwvTmjVr1Lp1a504cUKhoaGaM2eOnnjiCUnSjz/+qAYNGmj9+vVq2bJlsTEMw1BkZKQGDRqkwYPPx3LixAnVrFlTaWlp6t69e5liofIBAIC7WTDt8kcnTpyQJFWrVk2StGXLFhUUFKhdu3bOPvXr19dNN92k9evXlzjG3r17lZuba7omODhYLVq0KPWakrDgFAAAd3PRglOHwyGHw2Fqs9vtstvtF72uqKhIAwYM0L333qtGjRpJknJzc+Xn56eqVaua+tasWVO5ubkljnOhvWbNmmW+piRUPgAAuEakpqYqODjYdKSmpl7yun79+mnHjh2aO3euB6K8NCofAAC4m4seMjZs2DAlJyeb2i5V9XjxxRe1ePFiZWRk6MYbb3S2h4eH69y5czp+/Lip+nHw4EGFh4eXONaF9oMHDyoiIsJ0TbNmzcr8Pqh8AADgbi7a7WK32xUUFGQ6Sks+DMPQiy++qIULF2rlypWqW7eu6Xx0dLQqVqyoFStWONt27dql7OxstWrVqsQx69atq/DwcNM1J0+e1MaNG0u9piQkHwAAeKF+/frp73//u+bMmaPAwEDl5uYqNzdXZ86ckXR+oWifPn2UnJysVatWacuWLerVq5datWpl2ulSv359LVy4UJJks9k0YMAAvf7661q0aJG2b9+uxMRERUZGKiEhocyxMe0CAIC7WfDbLlOmTJEktWnTxtQ+c+ZM9ezZU5I0fvx4+fj46PHHH5fD4VBsbKwmT55s6r9r1y7nThlJeuWVV5Sfn69nn31Wx48f13333aelS5fK39+/zLHxnA/gOsJzPoDiPPKcj/jJl+5UBme+fMEl41iNaRcAAOBRTLsAAOBu/LCcCckHAADuZsGaj6sZyQcAAO5G5cOEVAwAAHgUlQ8AANyNaRcTkg8AANyNaRcTUjEAAOBRVD4AAHAzG5UPE5IPAADcjOTDjGkXAADgUVQ+AABwNwofJiQfAAC4GdMuZky7AAAAj6LyAQCAm1H5MCP5AADAzUg+zEg+AABwM5IPM9Z8AAAAj6LyAQCAu1H4MCH5AADAzZh2MWPaBQAAeBSVDwAA3IzKhxnJBwAAbkbyYca0CwAA8CgqHwAAuBmVDzOSDwAA3I3cw8TS5OPIkSOaMWOG1q9fr9zcXElSeHi47rnnHvXs2VOhoaFWhgcAANzAsjUfmzZt0m233aYJEyYoODhYrVu3VuvWrRUcHKwJEyaofv362rx5s1XhAQDgMjabzSWHt7Cs8vHSSy+pS5cumjp1arEP1DAMPf/883rppZe0fv16iyIEAMA1vClxcAXLko/vvvtOaWlpJf4HsdlsGjhwoJo3b25BZAAAuBbJh5ll0y7h4eH69ttvSz3/7bffqmbNmh6MCAAAeIJlycfgwYP17LPPqn///lq0aJE2btyojRs3atGiRerfv7+ef/55vfLKK1aFBwCA69hcdJRTRkaG4uPjFRkZKZvNpvT0dHNYpawtefvtt0sdMyUlpVj/+vXrlysuy6Zd+vXrpxo1amj8+PGaPHmyCgsLJUm+vr6Kjo5WWlqaunbtalV4AAC4jFXTLvn5+WratKl69+6tzp07Fzufk5Njev3111+rT58+evzxxy867u23367ly5c7X1eoUL50wtKttt26dVO3bt1UUFCgI0eOSJJq1KihihUrWhkWAABeIS4uTnFxcaWeDw8PN73+4osv1LZtW918880XHbdChQrFri2Pq+Lx6hUrVlRERIQiIiJIPAAAXuda2Gp78OBBffXVV+rTp88l++7evVuRkZG6+eab9dRTTyk7O7tc9+IJpwAAuJmrEgeHwyGHw2Fqs9vtstvtVzz2rFmzFBgYWOL0zO+1aNFCaWlpioqKUk5OjkaNGqX7779fO3bsUGBgYJnudVVUPgAAwKWlpqYqODjYdKSmprpk7BkzZuipp56Sv7//RfvFxcWpS5cuatKkiWJjY7VkyRIdP35cn376aZnvReUDAAA3c1XlY9iwYUpOTja1uaLq8c0332jXrl2aN29eua+tWrWqbrvtNu3Zs6fM11D5AADA3Vy01dZutysoKMh0uCL5mD59uqKjo9W0adNyX5uXl6esrCxFRESU+RpLKh+LFi0qc99HH33UjZEAAOC98vLyTBWJvXv3KjMzU9WqVdNNN90kSTp58qTmz5+vd955p8QxHnzwQT322GN68cUXJZ1/Tld8fLxq166tAwcOaOTIkfL19VWPHj3KHJclyUdCQkKZ+tlsNufzPwAAuFZZ9ZyPzZs3q23bts7XF6ZskpKSlJaWJkmaO3euDMMoNXnIyspyPg5Dkn755Rf16NFDR48eVWhoqO677z5t2LChXL9EbzMMw7iM93NVO/ub1REAV6eQu160OgTgqnNm20S33+PGF9JdMs4vkxNcMo7VWHAKAICb8cNyZldF8pGfn681a9YoOztb586dM517+eWXLYoKAAC4g+XJx7Zt29ShQwedPn1a+fn5qlatmo4cOaJKlSopLCyM5AMAcO2j8GFi+VbbgQMHKj4+XseOHVNAQIA2bNig/fv3Kzo6WuPGjbM6PAAArti18Hh1T7I8+cjMzNSgQYPk4+MjX19fORwO1apVS2PHjtXw4cOtDg8AALiY5dMuFStWlI/P+RwoLCxM2dnZatCggYKDg/Xzzz9bHB2uxNw5szVr5nQdOXJYt0XV16vDX1PjJk2sDgvwiMG9H1bCA011W52aOuMo0MbvftL/vP+Fdu8/JEkKCaqk1/p21IMt66tWeIiOHMvTl6u/16jJi3Uy76zF0cPVvKlq4QqWVz6aN2+uTZs2SZJiYmI0YsQIzZ49WwMGDFCjRo0sjg6Xa+nXSzRubKqee6Gf5s5fqKio+ur7XB8dPXrU6tAAj7j/jnqaOi9DMYnj9EjfiapQwVeLp7yoSv5+kqSI0GBFhAZr2PiFiu7ypp4Z+Xc9dE9DTR35lMWRwx2YdjGz/Dkfmzdv1qlTp9S2bVsdOnRIiYmJWrdunW699VbNmDHjsh71ynM+rPdU9y66vVFjDf/LCElSUVGRHn4wRj2e/LP6PPOsxdFdv3jOh3VqhFTRzyvfUrs+4/WvrVkl9uncrrlmvJGo6vcMUmFhkYcjvH554jkfdfovdsk4+95/xCXjWM3yaZc777zT+e9hYWFaunSphdHAFQrOndMP/96pPs8852zz8fFRy5b36PvvtlkYGWCdoCrnfyn02InTpfcJ9NfJ/LMkHl7Im6oWrmD5tAu8z7Hjx1RYWKjq1aub2qtXr256RC9wvbDZbHp78BNaty1L/87KKbFP9aqVNeyZOM34fJ2Ho4NHuOiH5byF5ZWPunXrXjQj/Omnny56vcPhkMPhMLUZvnaX/MofALjCe8O66vZ6EXqw1/gSzwdW9tfCCX31w085ev3DrzwcHeB5licfAwYMML0uKCjQtm3btHTpUg0ZMuSS16empmrUqFGmtv95baT+MiLFhVGiPEKqhsjX17fY4tKjR4+qRo0aFkUFWGP80C7qcH8jtevznv5z6Hix81Uq2bVo0gs6dfqsuiV/pN9+Y8rFGzHtYmZ58tG/f/8S2ydNmqTNmzdf8vphw4Y5f6XvAsOXqoeVKvr5qUHD27Vxw3o98GA7SecXnG7cuF7de/zJ4ugAzxk/tIsefaCpHn7mfe0/UHynV2Blf305uZ8c537TEwM+lOMcq+W9FcmH2VW75iMuLk6ff/75JfvZ7XYFBQWZDqZcrPfnpF5a8NmnWpS+UD9lZen10Sk6c+aMEh7rbHVogEe8N6yrune8S0nD05SXf1Y1qweqZvVA+dsrSjqfeCye3E+V/P30/KjZCqrs7+zj48MfVN7GZnPN4S0sr3yU5rPPPlO1atWsDgOXqX1cBx379VdNnjhBR44cVlT9Bpr84V9VnWkXXCee69pakrTsrwNM7c+M+Fh//3KjmtWvpbub1JUk/fvLFFOfqA4jlJ3zqyfCBCxhefLRvHlzUznKMAzl5ubq8OHDmjx5soWR4Ur1eOpP6vEU0yy4PgU0v/gzVb7ZsvuSfeA9mHYxszz56NSpk+k/io+Pj0JDQ9WmTRvVr1/fwsgAAHANcg8zy5OPlJQUq0MAAAAeZPmCU19fXx06dKhY+9GjR+Xr62tBRAAAuBa/7WJmeeWjtJ+WcTgc8vPz83A0AAC4nhflDS5hWfIxYcIESeezwb/+9a+qUqWK81xhYaEyMjJY8wEAgBeyLPkYP/78Y4YNw9DUqVNNUyx+fn6qU6eOpk6dalV4AAC4DM9uMbMs+di7d68kqW3btlqwYIFCQkKsCgUAALdi2sXM8jUfq1atsjoEAADgQZbvdnn88cf1v//7v8Xax44dqy5dulgQEQAArsVuFzPLk4+MjAx16NChWHtcXJwyMjIsiAgAANfit13MLJ92ycvLK3FLbcWKFXXy5EkLIgIAwLW8qWrhCpZXPho3bqx58+YVa587d64aNmxoQUQAAMCdLK98vPbaa+rcubOysrL0wAMPSJJWrFihTz75RPPnz7c4OgAArhyVDzPLk4/4+Hilp6frzTff1GeffaaAgAA1adJEy5cvV0xMjNXhAQBwxcg9zCxPPiSpY8eO6tixY7H2HTt2qFGjRhZEBAAA3MXyNR9/dOrUKU2bNk133323mjZtanU4AABcMau22mZkZCg+Pl6RkZGy2WxKT083ne/Zs2exe7Rv3/6S406aNEl16tSRv7+/WrRooW+//bZccV01yUdGRoYSExMVERGhcePG6YEHHtCGDRusDgsAgCtm1Vbb/Px8NW3aVJMmTSq1T/v27ZWTk+M8Pvnkk4uOOW/ePCUnJ2vkyJHaunWrmjZtqtjY2BJ/ob40lk675ObmKi0tTdOnT9fJkyfVtWtXORwOpaens9MFAIArFBcXp7i4uIv2sdvtCg8PL/OY7777rp555hn16tVLkjR16lR99dVXmjFjhl599dUyjWFZ5SM+Pl5RUVH6/vvv9d577+nAgQP64IMPrAoHAAC3uZqfcLp69WqFhYUpKipKffv21dGjR0vte+7cOW3ZskXt2rVztvn4+Khdu3Zav359me9pWeXj66+/1ssvv6y+ffvq1ltvtSoMAADczlV5g8PhkMPhMLXZ7XbZ7fbLGq99+/bq3Lmz6tatq6ysLA0fPlxxcXFav3696dfmLzhy5IgKCwtVs2ZNU3vNmjX1448/lvm+llU+1q5dq1OnTik6OlotWrTQxIkTdeTIEavCAQDgqpeamqrg4GDTkZqaetnjde/eXY8++qgaN26shIQELV68WJs2bdLq1atdF3QJLEs+WrZsqY8++kg5OTl67rnnNHfuXEVGRqqoqEjLli3TqVOnrAoNAACXctW0y7Bhw3TixAnTMWzYMJfFefPNN6tGjRras2dPiedr1KghX19fHTx40NR+8ODBcq0bsXy3S+XKldW7d2+tXbtW27dv16BBg/TWW28pLCxMjz76qNXhAQBwxVy128VutysoKMh0XO6US0l++eUXHT16VBERESWe9/PzU3R0tFasWOFsKyoq0ooVK9SqVasy38fy5OP3oqKiNHbsWP3yyy+X3OoDAMC1wqoFp3l5ecrMzFRmZqYkae/evcrMzFR2drby8vI0ZMgQbdiwQfv27dOKFSvUqVMn1atXT7Gxsc4xHnzwQU2cONH5Ojk5WR999JFmzZqlH374QX379lV+fr5z90tZXBVPOP0jX19fJSQkKCEhwepQAAC4Zm3evFlt27Z1vk5OTpYkJSUlacqUKfr+++81a9YsHT9+XJGRkXr44Yc1ZswYUzUlKyvLtCazW7duOnz4sEaMGKHc3Fw1a9ZMS5cuLbYI9WJshmEYLnh/V5Wzv1kdAXB1CrnrRatDAK46Z7ZNvHSnK9TyrTUuGWfDq97xm2dXZeUDAABvwq/aml1Vaz4AAID3o/IBAICbUfgwI/kAAMDNmHYxY9oFAAB4FJUPAADcjMKHGckHAABuxrSLGdMuAADAo6h8AADgZlQ+zEg+AABwM3IPM5IPAADcjMqHGWs+AACAR1H5AADAzSh8mJF8AADgZky7mDHtAgAAPIrKBwAAbkbhw4zkAwAAN/Mh+zBh2gUAAHgUlQ8AANyMwocZyQcAAG7Gbhczkg8AANzMh9zDhDUfAADAo6h8AADgZky7mJF8AADgZuQeZky7AAAAj6LyAQCAm9lE6eP3SD4AAHAzdruYMe0CAAA8isoHAABuxm4XM5IPAADcjNzDjGkXAADgUSQfAAC4mY/N5pKjvDIyMhQfH6/IyEjZbDalp6c7zxUUFGjo0KFq3LixKleurMjISCUmJurAgQMXHTMlJUU2m8101K9fv3yfR7nfCQAAKBebzTVHeeXn56tp06aaNGlSsXOnT5/W1q1b9dprr2nr1q1asGCBdu3apUcfffSS495+++3KyclxHmvXri1XXKz5AADAzaxacBoXF6e4uLgSzwUHB2vZsmWmtokTJ+ruu+9Wdna2brrpplLHrVChgsLDwy87LiofAABAknTixAnZbDZVrVr1ov12796tyMhI3XzzzXrqqaeUnZ1drvtQ+QAAwM1cVfhwOBxyOBymNrvdLrvdfsVjnz17VkOHDlWPHj0UFBRUar8WLVooLS1NUVFRysnJ0ahRo3T//fdrx44dCgwMLNO9qHwAAOBmrlpwmpqaquDgYNORmpp6xfEVFBSoa9euMgxDU6ZMuWjfuLg4denSRU2aNFFsbKyWLFmi48eP69NPPy3z/ah8AABwjRg2bJiSk5NNbVda9biQeOzfv18rV668aNWjJFWrVtVtt92mPXv2lPkaKh8AALiZzUWH3W5XUFCQ6biS5ONC4rF7924tX75c1atXL/cYeXl5ysrKUkRERJmvIfkAAMDN/vhcjMs9yisvL0+ZmZnKzMyUJO3du1eZmZnKzs5WQUGBnnjiCW3evFmzZ89WYWGhcnNzlZubq3PnzjnHePDBBzVx4kTn68GDB2vNmjXat2+f1q1bp8cee0y+vr7q0aNHmeNi2gUAAC+1efNmtW3b1vn6wpRNUlKSUlJStGjRIklSs2bNTNetWrVKbdq0kSRlZWXpyJEjznO//PKLevTooaNHjyo0NFT33XefNmzYoNDQ0DLHRfIBAICb+Vj02y5t2rSRYRilnr/YuQv27dtnej137twrDatsyceFzKgsyvJkNAAArif8qq1ZmZKPhISEMg1ms9lUWFh4JfEAAAAvV6bko6ioyN1xAADgtSh8mLHmAwAAN2Paxeyyko/8/HytWbNG2dnZpu04kvTyyy+7JDAAALyFVQtOr1blTj62bdumDh066PTp08rPz1e1atV05MgRVapUSWFhYSQfAADgosr9kLGBAwcqPj5ex44dU0BAgDZs2KD9+/crOjpa48aNc0eMAABc06x6yNjVqtzJR2ZmpgYNGiQfHx/5+vrK4XCoVq1aGjt2rIYPH+6OGAEAuKa56vHq3qLcyUfFihXl43P+srCwMGVnZ0uSgoOD9fPPP7s2OgAA4HXKveajefPm2rRpk2699VbFxMRoxIgROnLkiD7++GM1atTIHTECAHBN8/GiKRNXKHfl480333T+ct0bb7yhkJAQ9e3bV4cPH9a0adNcHiAAANc6m801h7cod+XjzjvvdP57WFiYli5d6tKAAACAd+MhYwAAuJk37VRxhXInH3Xr1r3oh/jTTz9dUUAAAHgbcg+zcicfAwYMML0uKCjQtm3btHTpUg0ZMsRVcQEAAC9V7uSjf//+JbZPmjRJmzdvvuKAAADwNux2MSv3bpfSxMXF6fPPP3fVcAAAeA12u5i5bMHpZ599pmrVqrlqOAAAvAYLTs0u6yFjv/8QDcNQbm6uDh8+rMmTJ7s0OAAA4H3KnXx06tTJlHz4+PgoNDRUbdq0Uf369V0aHADXOrZpotUhANcll61x8BLlTj5SUlLcEAYAAN6LaRezcidjvr6+OnToULH2o0ePytfX1yVBAQAA71XuyodhGCW2OxwO+fn5XXFAAAB4Gx8KHyZlTj4mTJgg6Xzp6K9//auqVKniPFdYWKiMjAzWfAAAUAKSD7MyJx/jx4+XdL7yMXXqVNMUi5+fn+rUqaOpU6e6PkIAAOBVypx87N27V5LUtm1bLViwQCEhIW4LCgAAb8KCU7Nyr/lYtWqVO+IAAMBrMe1iVu7dLo8//rj+93//t1j72LFj1aVLF5cEBQAAvFe5k4+MjAx16NChWHtcXJwyMjJcEhQAAN6E33YxK/e0S15eXolbaitWrKiTJ0+6JCgAALwJv2prVu7KR+PGjTVv3rxi7XPnzlXDhg1dEhQAAN7Ex0WHtyj3e3nttdc0ZswYJSUladasWZo1a5YSExP1+uuv67XXXnNHjAAA4DJkZGQoPj5ekZGRstlsSk9PN503DEMjRoxQRESEAgIC1K5dO+3evfuS406aNEl16tSRv7+/WrRooW+//bZccZU7+YiPj1d6err27NmjF154QYMGDdJ//vMfrVy5UvXq1SvvcAAAeD2r1nzk5+eradOmmjRpUonnx44dqwkTJmjq1KnauHGjKleurNjYWJ09e7bUMefNm6fk5GSNHDlSW7duVdOmTRUbG1viT6+UxmaU9rz0Mjp58qQ++eQTTZ8+XVu2bFFhYeGVDOcSZ3+zOgIAwLXCv9yrH8vvtaWXriaUxZj2t172tTabTQsXLlRCQoKk81WPyMhIDRo0SIMHD5YknThxQjVr1lRaWpq6d+9e4jgtWrTQXXfdpYkTz/9KdlFRkWrVqqWXXnpJr776apliuewppIyMDCUlJSkyMlLvvPOOHnjgAW3YsOFyhwMAAB60d+9e5ebmql27ds624OBgtWjRQuvXry/xmnPnzmnLli2ma3x8fNSuXbtSrylJufK93NxcpaWlafr06Tp58qS6du0qh8Oh9PR0FpsCAFAKV212cTgccjgcpja73S673V7usXJzcyVJNWvWNLXXrFnTee6Pjhw5osLCwhKv+fHHH8t87zJXPuLj4xUVFaXvv/9e7733ng4cOKAPPvigzDcCAOB65WNzzZGamqrg4GDTkZqaavXbK7cyVz6+/vprvfzyy+rbt69uvfXy55wAAMDlGTZsmJKTk01tl1P1kKTw8HBJ0sGDBxUREeFsP3jwoJo1a1biNTVq1JCvr68OHjxoaj948KBzvLIoc+Vj7dq1OnXqlKKjo9WiRQtNnDhRR44cKfONAAC4XvnYbC457Ha7goKCTMflJh9169ZVeHi4VqxY4Ww7efKkNm7cqFatWpV4jZ+fn6Kjo03XFBUVacWKFaVeU+LnUdaOLVu21EcffaScnBw999xzmjt3riIjI1VUVKRly5bp1KlTZb4pAADXE6u22ubl5SkzM1OZmZmSzi8yzczMVHZ2tmw2mwYMGKDXX39dixYt0vbt25WYmKjIyEjnjhhJevDBB507WyQpOTlZH330kWbNmqUffvhBffv2VX5+vnr16lXmuMq9wahy5crq3bu3evfurV27dmn69Ol666239Oqrr+qhhx7SokWLyjskAABwg82bN6tt27bO1xembJKSkpSWlqZXXnlF+fn5evbZZ3X8+HHdd999Wrp0qfz9/Z3XZGVlmWY6unXrpsOHD2vEiBHKzc1Vs2bNtHTp0mKLUC/mip/zIUmFhYX68ssvNWPGjKsi+eA5HwCAsvLEcz7eWLHHJeP8z4Pe8TBPlyQfVxuSDwBAWXki+XhzRZZLxhn+4C0uGcdqHvjIAQC4vvnwo7Ym3vQjeQAA4BpA5QMAADej8mFG8gEAgJvZXPV8dS/BtAsAAPAoKh8AALgZ0y5mJB8AALgZsy5mTLsAAACPovIBAICb+VD6MCH5AADAzVjzYca0CwAA8CgqHwAAuBmzLmYkHwAAuJmPyD5+j+QDAAA3o/JhxpoPAADgUVQ+AABwM3a7mJF8AADgZjznw4xpFwAA4FFUPgAAcDMKH2YkHwAAuBnTLmZMuwAAAI+i8gEAgJtR+DAj+QAAwM2YZjDj8wAAAB5F5QMAADezMe9iQvIBAICbkXqYkXwAAOBmbLU1Y80HAADwKCofAAC4GXUPM5IPAADcjFkXM6ZdAADwQnXq1JHNZit29OvXr8T+aWlpxfr6+/u7JTYqHwAAuJkVW203bdqkwsJC5+sdO3booYceUpcuXUq9JigoSLt27XK+dlfcJB8AALiZFdMMoaGhptdvvfWWbrnlFsXExJR6jc1mU3h4uLtDY9oFAABvd+7cOf39739X7969L1rNyMvLU+3atVWrVi116tRJO3fudEs8VD4AAHAzV01fOBwOORwOU5vdbpfdbr/odenp6Tp+/Lh69uxZap+oqCjNmDFDTZo00YkTJzRu3Djdc8892rlzp2688UZXhO9kMwzDcOmIV4Gzv1kdAQDgWuHvgb+Gz8884JJxdqZP06hRo0xtI0eOVEpKykWvi42NlZ+fn7788ssy36ugoEANGjRQjx49NGbMmMsJt1RUPgAAuEYMGzZMycnJprZLVT3279+v5cuXa8GCBeW6V8WKFdW8eXPt2bOn3HFeCskHAABu5qppl7JMsfzRzJkzFRYWpo4dO5brusLCQm3fvl0dOnQo13VlQfIBAICbWbW7o6ioSDNnzlRSUpIqVDD/kZ+YmKgbbrhBqampkqTRo0erZcuWqlevno4fP663335b+/fv19NPP+3yuEg+AABwMyue8yFJy5cvV3Z2tnr37l3sXHZ2tnx8/psWHTt2TM8884xyc3MVEhKi6OhorVu3Tg0bNnR5XCw4BQBc1zyx4HTh97kuGeexJu5/BocnUPkAAMDN+GkXs6v2IWM///xziWUiAACuNTabaw5vcdUmH7/++qtmzZpldRgAAMDFLJt2WbRo0UXP//TTTx6KBAAA9/Jh4sXEsuQjISFBNptNF1vvatXqYAAAXIk/zswsm3aJiIjQggULVFRUVOKxdetWq0IDAABuZFnyER0drS1btpR6/lJVEQAArhU2F/3jLSybdhkyZIjy8/NLPV+vXj2tWrXKgxEBAOAeTLuY8ZAxAMB1zRMPGVuy85BLxulwe5hLxrEaDxkDAMDN2O1iRvIBAICbMe1iRvIBAICbkXyYXbVPOAUAAN6JygcAAG7mTdtkXcGS5ONSj1b/vUcffdSNkQAA4H4+5B4mliQfCQkJZepns9lUWFjo3mAAAIBHWZJ8FBUVWXFbAAAswbSLGWs+AABwM3a7mF0VyUd+fr7WrFmj7OxsnTt3znTu5ZdftigqAADgDpYnH9u2bVOHDh10+vRp5efnq1q1ajpy5IgqVaqksLAwkg8AwDWPaRczy5/zMXDgQMXHx+vYsWMKCAjQhg0btH//fkVHR2vcuHFWhwcAwBXzsbnm8BaWJx+ZmZkaNGiQfHx85OvrK4fDoVq1amns2LEaPny41eEBAAAXszz5qFixonx8zocRFham7OxsSVJwcLB+/vlnK0PDFZo7Z7biHnpAdzVvrKe6d9H277+3OiTAcnwvrk82F/3jLSxPPpo3b65NmzZJkmJiYjRixAjNnj1bAwYMUKNGjSyODpdr6ddLNG5sqp57oZ/mzl+oqKj66vtcHx09etTq0ADL8L24ftlsrjm8heXJx5tvvqmIiAhJ0htvvKGQkBD17dtXhw8f1rRp0yyODpfr41kz1fmJrkp47HHdUq+e/jJylPz9/ZW+4HOrQwMsw/fi+mVz0eEtLN/tcueddzr/PSwsTEuXLrUwGrhCwblz+uHfO9XnmeecbT4+PmrZ8h59/902CyMDrMP3Avgvy5OPK+VwOORwOExthq9ddrvdoohw7PgxFRYWqnr16qb26tWra+/enyyKCrAW34vrm483zZm4gOXJR926dWW7yH+Un366+JcyNTVVo0aNMrX9z2sj9ZcRKa4IDwCAK0bqYWZ58jFgwADT64KCAm3btk1Lly7VkCFDLnn9sGHDlJycbGozfKl6WCmkaoh8fX2LLaI7evSoatSoYVFUgLX4XgD/ZXny0b9//xLbJ02apM2bN1/yeru9+BTL2d9cEhouU0U/PzVoeLs2blivBx5sJ+n8jwlu3Lhe3Xv8yeLoAGvwvbjOUfowsXy3S2ni4uL0+eesAL9W/TmplxZ89qkWpS/UT1lZen10is6cOaOExzpbHRpgGb4X1y+e82F21SYfn332mapVq2Z1GLhM7eM6KHnwUE2eOEFdH++kXT/+oMkf/lXVKS/jOsb3Ap6UkpIim81mOurXr3/Ra+bPn6/69evL399fjRs31pIlS9wSm+XTLs2bNzctODUMQ7m5uTp8+LAmT55sYWS4Uj2e+pN6PEU5Gfg9vhfXJ6s2u9x+++1avny583WFCqX/sb9u3Tr16NFDqampeuSRRzRnzhwlJCRo69atLn/op+XJR6dOnUzJh4+Pj0JDQ9WmTZtLZmgAAFwLrJowqVChgsLDw8vU9/3331f79u2dmz3GjBmjZcuWaeLEiZo6dapr43LpaJchJSXF6hAAAPBKu3fvVmRkpPz9/dWqVSulpqbqpptuKrHv+vXri+0ejY2NVXp6usvjsnzNh6+vrw4dOlSs/ejRo/L19bUgIgAAXMxFz1d3OBw6efKk6fjjgzYvaNGihdLS0rR06VJNmTJFe/fu1f33369Tp06V2D83N1c1a9Y0tdWsWVO5ublX+u6LsTz5MAyjxHaHwyE/Pz8PRwMAgOu5ardLamqqgoODTUdqamqJ94yLi1OXLl3UpEkTxcbGasmSJTp+/Lg+/fRTD7/74iybdpkwYYIkyWaz6a9//auqVKniPFdYWKiMjAzWfAAAvIKrFpyW9GDNsv6cSNWqVXXbbbdpz549JZ4PDw/XwYMHTW0HDx4s85qR8rAs+Rg/fryk85WPqVOnmqZY/Pz8VKdOHZcvcAEA4FpW0oM1yyovL09ZWVn685//XOL5Vq1aacWKFaYnjy9btkytWrW6rPtdjGXJx969eyVJbdu21YIFCxQSEmJVKAAAuJUVu10GDx6s+Ph41a5dWwcOHNDIkSPl6+urHj16SJISExN1ww03OKdt+vfvr5iYGL3zzjvq2LGj5s6dq82bN2vatGkuj83y3S6rVq2yOgQAANzLguzjl19+UY8ePXT06FGFhobqvvvu04YNGxQaGipJys7Olo/Pf5d+3nPPPZozZ47+8pe/aPjw4br11luVnp7u8md8SJLNKG3Fp4c8/vjjuvvuuzV06FBT+9ixY7Vp0ybNnz+/3GPy2y4AgLLy98Bfw7fuP+mSce6oHeSScaxm+W6XjIwMdejQoVh7XFycMjIyLIgIAADX4rddzCyfdsnLyytxS23FihV18qRrMkUAAKxk1ePVr1aWVz4aN26sefPmFWufO3euGjZsaEFEAADAnSyvfLz22mvq3LmzsrKy9MADD0iSVqxYoU8++eSy1nsAAHC1ofBhZnnyER8fr/T0dL355pv67LPPFBAQoCZNmmj58uWKiYmxOjwAAK4c2YeJ5btdLmbHjh2XtcWH3S4AgLLyxG6X734u+fdUyqtprUCXjGM1y9d8/NGpU6c0bdo03X333WratKnV4QAAcMXY7WJ21SQfGRkZSkxMVEREhMaNG6cHHnhAGzZssDosAACumM3mmsNbWLrmIzc3V2lpaZo+fbpOnjyprl27yuFwKD09nZ0uAACv4UV5g0tYVvmIj49XVFSUvv/+e7333ns6cOCAPvjgA6vCAQAAHmJZ5ePrr7/Wyy+/rL59++rWW2+1KgwAANyP0oeJZZWPtWvX6tSpU4qOjlaLFi00ceJEHTlyxKpwAABwGxacmlmWfLRs2VIfffSRcnJy9Nxzz2nu3LmKjIxUUVGRli1bplOnXLMtCQAAXF2uqud87Nq1S9OnT9fHH3+s48eP66GHHtKiRYvKPQ7P+QAAlJUnnvPx7wP5LhmnYWRll4xjtatmq60kRUVFaezYsfrll1/0ySefWB0OAAAuYXPR4S2uqsqHq1D5AACUlScqHz+4qPLRwEsqH5b/tgsAAF7Pm8oWLkDyAQCAm3nTThVXuKrWfAAAAO9H5QMAADfzpt9lcQWSDwAA3Izcw4zkAwAAdyP7MGHNBwAA8CgqHwAAuBm7XcxIPgAAcDMWnJox7QIAADyKygcAAG5G4cOM5AMAAHcj+zBh2gUAAHgUlQ8AANyM3S5mJB8AALgZu13MmHYBAMALpaam6q677lJgYKDCwsKUkJCgXbt2XfSatLQ02Ww20+Hv7+/y2Eg+AABwM5uLjvJYs2aN+vXrpw0bNmjZsmUqKCjQww8/rPz8/IteFxQUpJycHOexf//+ct750ph2AQDA3SyYdlm6dKnpdVpamsLCwrRlyxa1bt261OtsNpvCw8PdGhuVDwAA3Mzmon+uxIkTJyRJ1apVu2i/vLw81a5dW7Vq1VKnTp20c+fOK7pvSWyGYRguH9ViZ3+zOgIAwLXC3wNzAPuPOlwyTngVyeEwj2W322W32y96XVFRkR599FEdP35ca9euLbXf+vXrtXv3bjVp0kQnTpzQuHHjlJGRoZ07d+rGG290yXuQqHwAAOB2NptrjtTUVAUHB5uO1NTUS96/X79+2rFjh+bOnXvRfq1atVJiYqKaNWummJgYLViwQKGhofrwww9d9VFIovIBALjOeaLy8fOvrql8hFUuf+XjxRdf1BdffKGMjAzVrVu33Pfs0qWLKlSooE8++aTc15aGBacAAFwjyjLFcoFhGHrppZe0cOFCrV69+rISj8LCQm3fvl0dOnQo97UXQ/IBAICbWfGQsX79+mnOnDn64osvFBgYqNzcXElScHCwAgICJEmJiYm64YYbnFM3o0ePVsuWLVWvXj0dP35cb7/9tvbv36+nn37apbGRfAAA4Haezz6mTJkiSWrTpo2pfebMmerZs6ckKTs7Wz4+/13+eezYMT3zzDPKzc1VSEiIoqOjtW7dOjVs2NClsbHmAwBwXfPEmo9fjp1zyTg3hvi5ZByrUfkAAMDN+G0XM5IPAADcjNzDjOd8AAAAj6LyAQCAmzHtYkbyAQCAm13p77J4G5IPAADcjdzDhDUfAADAo6h8AADgZhQ+zEg+AABwMxacmjHtAgAAPIrKBwAAbsZuFzOSDwAA3I3cw4RpFwAA4FFUPgAAcDMKH2YkHwAAuBm7XcyYdgEAAB5F5QMAADdjt4sZyQcAAG7GtIsZ0y4AAMCjSD4AAIBHMe0CAICbMe1iRvIBAICbseDUjGkXAADgUVQ+AABwM6ZdzEg+AABwM3IPM6ZdAACAR1H5AADA3Sh9mJB8AADgZux2MWPaBQAAeBSVDwAA3IzdLmYkHwAAuBm5hxnTLgAAuJvNRcdlmDRpkurUqSN/f3+1aNFC33777UX7z58/X/Xr15e/v78aN26sJUuWXN6NL4LkAwAALzVv3jwlJydr5MiR2rp1q5o2barY2FgdOnSoxP7r1q1Tjx491KdPH23btk0JCQlKSEjQjh07XBqXzTAMw6UjXgXO/mZ1BACAa4W/BxYgnClwzTgBFcvXv0WLFrrrrrs0ceJESVJRUZFq1aqll156Sa+++mqx/t26dVN+fr4WL17sbGvZsqWaNWumqVOnXlHsv0flAwAAN7PZXHOUx7lz57Rlyxa1a9fO2ebj46N27dpp/fr1JV6zfv16U39Jio2NLbX/5WLBKQAA1wiHwyGHw2Fqs9vtstvtxfoeOXJEhYWFqlmzpqm9Zs2a+vHHH0scPzc3t8T+ubm5Vxi5mVcmH54ooeHSHA6HUlNTNWzYsBK/GMD1iu/G9cdVfy6lvJ6qUaNGmdpGjhyplJQU19zAQ5h2gds4HA6NGjWqWJYOXO/4buByDRs2TCdOnDAdw4YNK7FvjRo15Ovrq4MHD5raDx48qPDw8BKvCQ8PL1f/y0XyAQDANcJutysoKMh0lFY98/PzU3R0tFasWOFsKyoq0ooVK9SqVasSr2nVqpWpvyQtW7as1P6XiwkKAAC8VHJyspKSknTnnXfq7rvv1nvvvaf8/Hz16tVLkpSYmKgbbrhBqampkqT+/fsrJiZG77zzjjp27Ki5c+dq8+bNmjZtmkvjIvkAAMBLdevWTYcPH9aIESOUm5urZs2aaenSpc5FpdnZ2fLx+e8kyD333KM5c+boL3/5i4YPH65bb71V6enpatSokUvj8srnfODqwKI6oGR8N3C9I/kAAAAexYJTAADgUSQfAADAo0g+AACAR5F8oNx69uyphIQE5+s2bdpowIABHo9j9erVstlsOn78uMfvDZSE7wZQNiQfXqJnz56y2Wyy2Wzy8/NTvXr1NHr0aP32m/t/4nfBggUaM2ZMmfp6+n+KZ8+eVb9+/VS9enVVqVJFjz/+eLGn98G78d0o2bRp09SmTRsFBQWRqMDjSD68SPv27ZWTk6Pdu3dr0KBBSklJ0dtvv11i33PnzrnsvtWqVVNgYKDLxnOlgQMH6ssvv9T8+fO1Zs0aHThwQJ07d7Y6LHgY343iTp8+rfbt22v48OFWh4LrEMmHF7Hb7QoPD1ft2rXVt29ftWvXTosWLZL033LwG2+8ocjISEVFRUmSfv75Z3Xt2lVVq1ZVtWrV1KlTJ+3bt885ZmFhoZKTk1W1alVVr15dr7zyiv64O/uPpWWHw6GhQ4eqVq1astvtqlevnqZPn659+/apbdu2kqSQkBDZbDb17NlT0vlH/qampqpu3boKCAhQ06ZN9dlnn5nus2TJEt12220KCAhQ27ZtTXGW5MSJE5o+fbreffddPfDAA4qOjtbMmTO1bt06bdiw4TI+YVyr+G4UN2DAAL366qtq2bJlOT9N4MqRfHixgIAA09/iVqxYoV27dmnZsmVavHixCgoKFBsbq8DAQH3zzTf617/+pSpVqqh9+/bO69555x2lpaVpxowZWrt2rX799VctXLjwovdNTEzUJ598ogkTJuiHH37Qhx9+qCpVqqhWrVr6/PPPJUm7du1STk6O3n//fUlSamqq/va3v2nq1KnauXOnBg4cqD/96U9as2aNpPN/EHTu3Fnx8fHKzMzU008/rVdfffWicWzZskUFBQVq166ds61+/fq66aabtH79+vJ/oPAa1/t3A7CcAa+QlJRkdOrUyTAMwygqKjKWLVtm2O12Y/Dgwc7zNWvWNBwOh/Oajz/+2IiKijKKioqcbQ6HwwgICDD+8Y9/GIZhGBEREcbYsWOd5wsKCowbb7zReS/DMIyYmBijf//+hmEYxq5duwxJxrJly0qMc9WqVYYk49ixY862s2fPGpUqVTLWrVtn6tunTx+jR48ehmEYxrBhw4yGDRuazg8dOrTYWL83e/Zsw8/Pr1j7XXfdZbzyyislXgPvw3fj4kq6L+Bu/LaLF1m8eLGqVKmigoICFRUV6cknn1RKSorzfOPGjeXn5+d8/d1332nPnj3F5qTPnj2rrKwsnThxQjk5OWrRooXzXIUKFXTnnXcWKy9fkJmZKV9fX8XExJQ57j179uj06dN66KGHTO3nzp1T8+bNJUk//PCDKQ5JLv+VRXgvvhvA1YXkw4u0bdtWU6ZMkZ+fnyIjI1Whgvk/b+XKlU2v8/LyFB0drdmzZxcbKzQ09LJiCAgIKPc1eXl5kqSvvvpKN9xwg+nclfzuRXh4uM6dO6fjx4+ratWqzvaDBw8qPDz8ssfFtYfvBnB1IfnwIpUrV1a9evXK3P+OO+7QvHnzFBYWpqCgoBL7REREaOPGjWrdurUk6bffftOWLVt0xx13lNi/cePGKioq0po1a0xrLS648LfLwsJCZ1vDhg1lt9uVnZ1d6t8KGzRo4FwgeMGlFo1GR0erYsWKWrFihR5//HFJ5+fTs7Oz+ZvhdYbvBnB1YcHpdeypp55SjRo11KlTJ33zzTfau3evVq9erZdfflm//PKLJKl///566623lJ6erh9//FEvvPDCRZ8HUKdOHSUlJal3795KT093jvnpp59KkmrXri2bzabFixfr8OHDysvLU2BgoAYPHqyBAwdq1qxZysrK0tatW/XBBx9o1qxZkqTnn39eu3fv1pAhQ7Rr1y7NmTNHaWlpF31/wcHB6tOnj5KTk7Vq1Spt2bJFvXr1UqtWrVjhj4vy9u+GJOXm5iozM1N79uyRJG3fvl2ZmZn69ddfr+zDA8rC6kUncI3fL6orz/mcnBwjMTHRqFGjhmG3242bb77ZeOaZZ4wTJ04YhnF+EV3//v2NoKAgo2rVqkZycrKRmJhY6qI6wzCMM2fOGAMHDjQiIiIMPz8/o169esaMGTOc50ePHm2Eh4cbNpvNSEpKMgzj/ELA9957z4iKijIqVqxohIaGGrGxscaaNWuc13355ZdGvXr1DLvdbtx///3GjBkzLrlQ7syZM8YLL7xghISEGJUqVTIee+wxIycn56KfJbwL342SjRw50pBU7Jg5c+bFPk7AJWyGUcrqKAAAADdg2gUAAHgUyQcAAPAokg8AAOBRJB8AAMCjSD4AAIBHkXwAAACPIvkAAAAeRfIBeKGePXsqISHB+bpNmzYaMGCAx+NYvXq1bDbbRZ/8CeD6Q/IBeFDPnj1ls9lks9nk5+enevXqafTo0frtt9/cet8FCxZozJgxZepLwgDA3fhhOcDD2rdvr5kzZ8rhcGjJkiXq16+fKlasqGHDhpn6nTt3zvQz71eiWrVqLhkHAFyBygfgYXa7XeHh4apdu7b69u2rdu3aadGiRc6pkjfeeEORkZGKioqSJP3888/q2rWrqlatqmrVqqlTp07at2+fc7zCwkIlJyeratWqql69ul555RX98VcT/jjt4nA4NHToUNWqVUt2u1316tXT9OnTtW/fPrVt21aSFBISIpvNpp49e0qSioqKlJqaqrp16yogIEBNmzbVZ599ZrrPkiVLdNtttykgIEBt27Y1xQkAF5B8ABYLCAjQuXPnJEkrVqzQrl27tGzZMi1evFgFBQWKjY1VYGCgvvnmG/3rX/9SlSpV1L59e+c177zzjtLS0jRjxgytXbtWv/76qxYuXHjReyYmJuqTTz7RhAkT9MMPP+jDDz9UlSpVVKtWLX3++eeSpF27diknJ0fvv/++JCk1NVV/+9vfNHXqVO3cuVMDBw7Un/70J61Zs0bS+SSpc+fOio+PV2Zmpp5++mm9+uqr7vrYAFzLLP5hO+C68vtfUC0qKjKWLVtm2O12Y/DgwUZSUpJRs2ZNw+FwOPt//PHHRlRUlFFUVORsczgcRkBAgPGPf/zDMAzDiIiIMMaOHes8X1BQYNx4442l/rrqrl27DEnGsmXLSoxx1apVxX4R9ezZs0alSpWMdevWmfr26dPH6NGjh2EYhjFs2DCjYcOGpvNDhw695K+rArj+sOYD8LDFixerSpUqKigoUFFRkZ588kmlpKSoX79+aty4sWmdx3fffac9e/YoMDDQNMbZs2eVlZWlEydOKCcnRy1atHCeq1Chgu68885iUy8XZGZmytfXVzExMWWOec+ePTp9+rQeeughU/u5c+fUvHlzSdIPP/xgikOSWrVqVeZ7ALh+kHwAHta2bVtNmTJFfn5+ioyMVIUK//0aVq5c2dQ3Ly9P0dHRmj17drFxQkNDL+v+AQEB5b4mLy9PkvTVV1/phhtuMJ2z2+2XFQeA6xfJB+BhlStXVr169crU94477tC8efMUFhamoKCgEvtERERo48aNat26tSTpt99+05YtW3THHXeU2L9x48YqKirSmjVr1K5du2LnL1ReCgsLnW0NGzaU3W5XdnZ2qRWTBg0aaNGiRaa2DRs2XPpNArjusOAUuIo99dRTqlGjhjp16qRvvvlGe/fu1erVq/Xyyy/rl19+kST1799fb731ltLT0/Xjjz/qhRdeuOgzOurUqaOkpCT17t1b6enpzjE//fRTSVLt2rVls9m0ePFiHT58WHl5eQoMDNTgwYM1cOBAzZo1S1lZWdq6das++OADzZo1S5L0/PPPa/fu3RoyZIh27dqlOXPmKC0tzd0fEYBrEMkHcBWrVKmSMjIydNNNN6lz585q0KCB+vTpo7NnzzorIYMGDdKf//xnJSUlqVWrVgoMDNRjjz120XGnTJmiJ554Qi+88ILq16+vZ555Rvn5+ZKkG264QaNGjdKrr76qmjVr6sUXX5QkjRkzRq+99ppSU1PVoEEDtW/fXl999ZXq1q0rSbrpppv0+eefKz09XU2bNtXUqVP15ptvuvHTAXCtshmlrUoDAABwAyofAADAo0g+AACAR5F8AAAAjyL5AAAAHkXyAQAAPIrkAwAAeBTJBwAA8CiSDwAA4FEkHwAAwKNIPgAAgEeRfAAAAI8i+QAAAB71//Dst0s+dvueAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "y_pred=model.predict(fest_data)\n",
    "y_test=np.zeros((22,))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# Plot the confusion matrix using Seaborn\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
